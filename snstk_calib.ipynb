{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPa4uiQsEF3Go1hyxlREvt5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttheimeroo/ttheimeroo.github.io/blob/main/snstk_calib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Python Functions for SensTek Calibration\n",
        "Tom Theimer 8/25/2023\n",
        "\n",
        "This is a development and testing sheet for a Python module of functions to support calibration processing and moving of data to the SensTek database.\n",
        "\n",
        "There is an associated test harness file \"snstk_calib_py_TH.ipynb\" (in the calibration folder) for verification of the individual module functions."
      ],
      "metadata": {
        "id": "0HrVHHyO2TqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get a MySQL Connection - prod"
      ],
      "metadata": {
        "id": "gZZ6FnpluxmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_mysql_connection():\n",
        "  \"\"\"The shell command\n",
        "  !pip3 install mysql-connector-python\n",
        "  must be run in the main program before calling this function\n",
        "  \"\"\"\n",
        "  # MySQL setup\n",
        "  import mysql.connector\n",
        "\n",
        "  # Connection settings\n",
        "  mysql_config = {\n",
        "     \"host\": \"data.snstk.com\",\n",
        "     \"user\": \"colab1\",\n",
        "     \"password\": \"3liLLLy&poot\",\n",
        "     \"database\": \"sensordata\"\n",
        "  }\n",
        "\n",
        "  # Create a MySQL connection\n",
        "  return mysql.connector.connect(**mysql_config) # the double asterisk\n",
        "  #                 unpacks the dictionary into key-value pairs which\n",
        "  #                 it applies are arguments to a function."
      ],
      "metadata": {
        "id": "dQIMCebvKvFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get a MySQL Connection - CLONE"
      ],
      "metadata": {
        "id": "-i8Gai2Zu-A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_mysql_CLONE_connection():\n",
        "  \"\"\"The shell command\n",
        "  !pip3 install mysql-connector-python\n",
        "  must be run in the main program before calling this function\n",
        "  \"\"\"\n",
        "  # MySQL setup\n",
        "  import mysql.connector\n",
        "\n",
        "  # Connection settings\n",
        "  mysql_config = {\n",
        "     \"host\": \"data.snstk.com\",\n",
        "     \"user\": \"colab1\",\n",
        "     \"password\": \"3liLLLy&poot\",\n",
        "     \"database\": \"sensorclone\"\n",
        "  }\n",
        "\n",
        "  # Create a MySQL connection\n",
        "  return mysql.connector.connect(**mysql_config) # the double asterisk\n",
        "  #                 unpacks the dictionary into key-value pairs which\n",
        "  #                 it applies are arguments to a function."
      ],
      "metadata": {
        "id": "bnm2c0YbNQKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Quotes in String or NULL\n",
        "This preps a string for a MySQL INSERT statement. Included quotes or NULL for None"
      ],
      "metadata": {
        "id": "45_IKkUBvKF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to prep a value for MySQL INSERT stmt. Return a value that includes quotes if needed.\n",
        "def mysqlprep(insertvalstr):\n",
        "  if insertvalstr == None:\n",
        "    return \"Null\"\n",
        "  elif (isinstance(insertvalstr, (int, float, complex)) or\n",
        "        insertvalstr.isnumeric()):\n",
        "    return insertvalstr\n",
        "  else:\n",
        "    return f\"'{insertvalstr}'\""
      ],
      "metadata": {
        "id": "56v7iWUXB1NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Escape single quotes"
      ],
      "metadata": {
        "id": "o39RzA_Wv4Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to escape single quotes\n",
        "def escape_single_quotes(input_string):\n",
        "    return input_string.replace(\"'\", \"\\\\'\")"
      ],
      "metadata": {
        "id": "W9aycfUMC0zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##read_data_from_param_sprdsht()"
      ],
      "metadata": {
        "id": "wCSXE4akwOGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtslGQONtsEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5fb134-ff6b-4f82-bcb1-fd154c1497de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# This mount routine is required to alow connection to files in Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6258f36-0a23-4262-a95a-53093c62a151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "5f4cad3b-3834-4efe-885f-8fc993c9b7f2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7fab9ffc7920>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtestdefn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mread_data_from_param_sprdsht\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/Shared drives/SNSTK (Public)/5000 ENGINEERING/Reader/_TESTING/Calibration/202311/28/20231128_Calib_1x1341_1342_cycle_1_CUST.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-7fab9ffc7920>\u001b[0m in \u001b[0;36mread_data_from_param_sprdsht\u001b[0;34m(ss_file_path)\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mbuffer_start_stop_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlists_row\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0mbuffer_start_stop_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'buffer_pH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'start_time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stop_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0mbuffer_start_stop_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m   \u001b[0mtestdefn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'buffer_start_stop_df'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer_start_stop_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;31m#testdefn['start_stop_dct'] = buffer_start_stop_df.to_dict(orient='records') #not used??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6921\u001b[0m                 \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6923\u001b[0;31m             indexer = nargsort(\n\u001b[0m\u001b[1;32m   6924\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6925\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/sorting.py\u001b[0m in \u001b[0;36mnargsort\u001b[0;34m(items, kind, ascending, na_position, key, mask)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mnon_nans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_nans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mnon_nan_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_nan_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m     \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnon_nan_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnon_nans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'datetime.time'"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Function to read the Parameter file (xlsx) and move the test parameters into variables.\n",
        "The input parameter is the full file path.\n",
        "A dictionary is returned. Most keys refer to single data elements with the\n",
        "exception of the keys \"rs_pairs_df\" and \"buffer_start_stop_df\" which refer to\n",
        "dataframes.\n",
        "\"\"\"\n",
        "def read_data_from_param_sprdsht(ss_file_path):\n",
        "  import pandas as pd\n",
        "  df = pd.read_excel(ss_file_path, sheet_name='Seq_params', usecols=\"A:H\")\n",
        "\n",
        "  testdefn = {}\n",
        "  testdefn['param_full_file_path'] = ss_file_path\n",
        "  testdefn['testing_lab'] = df.iloc[df.iloc[:,0:1].isin(['testing_lab']).idxmax()[0] ,1]\n",
        "  testdefn['timezone_utc_offset'] = df.iloc[df.iloc[:,0:1].isin(['timezone offset']).idxmax()[0] ,1]\n",
        "  testdefn['technician'] = df.iloc[df.iloc[:,0:1].isin(['technician']).idxmax()[0] ,1]\n",
        "  testdefn['we_source'] = df.iloc[df.iloc[:,0:1].isin(['WE source']).idxmax()[0] ,1]\n",
        "  testdefn['re_source'] = df.iloc[df.iloc[:,0:1].isin(['RE source']).idxmax()[0] ,1]\n",
        "  testdefn['test_type'] = df.iloc[df.iloc[:,0:1].isin(['test type']).idxmax()[0] ,1]\n",
        "  testdefn['time_in_buffer_min'] = df.iloc[df.iloc[:,0:1].isin(['time in buffer']).idxmax()[0] ,1]\n",
        "  testdefn['conditioning_time_min'] = df.iloc[df.iloc[:,0:1].isin(['conditioning time']).idxmax()[0] ,1]\n",
        "  testdefn['conditioning_substance'] = df.iloc[df.iloc[:,0:1].isin(['cond. substance']).idxmax()[0] ,1]\n",
        "  testdefn['test_date'] = df.iloc[df.iloc[:,0:1].isin(['Test Date']).idxmax()[0] ,1].date()\n",
        "  testdefn['sample_sec_for_calcs'] = df.iloc[df.iloc[:,0:1].isin(['sample calc dur']).idxmax()[0] ,1]\n",
        "  testdefn['sample_start_sec'] = df.iloc[df.iloc[:,0:1].isin(['sample calc start']).idxmax()[0] ,1]\n",
        "  testdefn['comments'] = df.iloc[df.iloc[:,0:1].isin(['comments']).idxmax()[0] ,1]\n",
        "  if not (isinstance(testdefn['time_in_buffer_min'], (int, float, complex)) or\n",
        "          testdefn['time_in_buffer_min'].isnumeric()):\n",
        "    testdefn['comments'] += f\"\\nThe duration in buffer was: \\\"{testdefn['time_in_buffer_min']}\\\"\"\n",
        "    testdefn['time_in_buffer_min'] = None\n",
        "  lists_row = df.iloc[:,0:1].isin(['Sensor & Buffer Tables']).idxmax()[0] + 2\n",
        "  rs_pairs_df = df.iloc[lists_row:, 2:4].dropna(axis = 0, how = 'all')\n",
        "  rs_pairs_df.columns = ['reader_sn','sensor_id']\n",
        "  rs_pairs_df['reader_sn'] = rs_pairs_df['reader_sn'].astype(int)\n",
        "  rs_pairs_df['sensor_id'] = rs_pairs_df['sensor_id'].astype(int)\n",
        "  #testdefn['rs_pairs_dct'] = rs_pairs_df.to_dict(orient='records') #not used??\n",
        "  testdefn['rs_pairs_df'] = rs_pairs_df\n",
        "\n",
        "  buffer_start_stop_df = df.iloc[lists_row:,5:8].dropna(axis = 0, how = 'all')\n",
        "  buffer_start_stop_df.columns = ['buffer_pH', 'start_time', 'stop_time']\n",
        "  buffer_start_stop_df.sort_values(by=['start_time'], inplace=True)\n",
        "  testdefn['buffer_start_stop_df'] = buffer_start_stop_df\n",
        "  #testdefn['start_stop_dct'] = buffer_start_stop_df.to_dict(orient='records') #not used??\n",
        "  testdefn['first_start_time'] = buffer_start_stop_df.iloc[0].at['start_time']\n",
        "  testdefn['last_stop_time'] = buffer_start_stop_df.iloc[-1].at['stop_time']\n",
        "  reader_ser = rs_pairs_df['reader_sn'] #This is for the next line\n",
        "  testdefn['readerlststr'] = ','.join(map(str, reader_ser.tolist())) # used for documentatn\n",
        "\n",
        "  return testdefn\n",
        "read_data_from_param_sprdsht('/content/drive/Shared drives/SNSTK (Public)/5000 ENGINEERING/Reader/_TESTING/Calibration/202311/28/20231128_Calib_1x1341_1342_cycle_1_CUST.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Push param data to DB"
      ],
      "metadata": {
        "id": "Y_AnKt1nwVl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Push parameter data (from the spreadsheet) to the database table TstCycle.\n",
        "(TCKey will be auto-populated)\n",
        "@param \"cnx\" MySQL connection object.\n",
        "@param \"paramdct\" Dictionary of test parameters.\n",
        "\"\"\"\n",
        "def params_to_sql(cnx, paramdct):\n",
        "  # Create a cursor object to execute SQL queries\n",
        "  cursor = cnx.cursor()\n",
        "\n",
        "  param_full_file_path = paramdct['param_full_file_path']\n",
        "  onetestdate = paramdct['test_date']\n",
        "  onetestinglab = paramdct['testing_lab']\n",
        "  onetech = paramdct['technician']\n",
        "  onetesttype = paramdct['test_type']\n",
        "  onesamplewait = paramdct['sample_start_sec']\n",
        "  onesampledur = paramdct['sample_sec_for_calcs']\n",
        "  onetestnotes = paramdct['comments']\n",
        "  immersion_min_q = mysqlprep(paramdct['time_in_buffer_min'])\n",
        "  cond_min = paramdct['conditioning_time_min']\n",
        "  cond_sub = paramdct['conditioning_substance']\n",
        "  first_start = paramdct['first_start_time']\n",
        "  last_end = paramdct['last_stop_time']\n",
        "  query = (\"INSERT IGNORE into TstCycle \" +\n",
        "          \"(TCSprdShtName,TCDate,TCLab,TCTech,TCType,TCDurInBuffer,\" +\n",
        "          \"TCConditioningMin,TCCondSubstance,TCSampleStart,TCSampleDur,\" +\n",
        "          \"TCFirstStartTime,TCLastEndTIme,TCNotes) VALUES \" +\n",
        "          f\"('{param_full_file_path}','{onetestdate}','{onetestinglab}','{onetech}',\" +\n",
        "            f\"'{onetesttype}',{immersion_min_q},{cond_min},'{cond_sub}',\" +\n",
        "            f\"{onesamplewait},{onesampledur},'{first_start}','{last_end}',\" +\n",
        "            f\"'{escape_single_quotes(onetestnotes)}');\")\n",
        "  print(f'From params_to_sql(): {query}')\n",
        "  cursor.execute(query)\n",
        "  #print(\"Inserting \" + param_full_file_path)\n",
        "  cnx.commit()\n",
        "  cursor.execute('SELECT LAST_INSERT_ID();')\n",
        "  last_tc_key = cursor.fetchone()[0]\n",
        "  cursor.close()         # It should not be necessary to close and open the\n",
        "  cursor = cnx.cursor()  # cursor but the following INSERTs are not working. Still not working... but no error.\n",
        "  # Converting to Dict below because the loop to push the data to MySQL\n",
        "  # was written for Dict structure. It can be refactored to loop through\n",
        "  # the DataFrame.  Same with rs_pairs_dct below.\n",
        "  start_stop_dct = paramdct['buffer_start_stop_df'].to_dict(orient='records')\n",
        "  # start_stop_dct: [{'buffer_pH': 3, 'start_time': datetime.time(12, 17, 5), 'stop_time': datetime.time(12, 22, 5)}\n",
        "  for onebuf in start_stop_dct:\n",
        "    buf = onebuf['buffer_pH']\n",
        "    starttime = onebuf['start_time'].strftime('%H:%M:%S')\n",
        "    stoptime = onebuf['stop_time'].strftime('%H:%M:%S')\n",
        "    query = (\"INSERT IGNORE INTO `TstTimes` (TTTCFK,TTbufpH,TTstarttime,TTendtime) \" +\n",
        "            \"VALUES\" +\n",
        "            f\"({last_tc_key},{buf},'{starttime}','{stoptime}');\")\n",
        "    print(query)\n",
        "    cursor.execute(query)\n",
        "    cnx.commit()\n",
        "\n",
        "  rs_pairs_dct = paramdct['rs_pairs_df'].to_dict(orient='records')\n",
        "  # rs_pairs_dct: [{'reader_sn': 216, 'sensor_id': 1001204}, {'reader_sn': 236, 'sensor_id': 1001185}, {'reader_sn': 247, 'sensor_id': 1001161}]\n",
        "  for onepair in rs_pairs_dct:\n",
        "    readersn = onepair['reader_sn']\n",
        "    sensorid = onepair['sensor_id']\n",
        "    query = (\"INSERT IGNORE INTO `RSPairs` (RSTCFK,RSRdrSNFK,RSSensFK) \" +\n",
        "            \"VALUES\" +\n",
        "            f\"({last_tc_key},{readersn},{sensorid});\")\n",
        "    print(query)\n",
        "    cursor.execute(query)\n",
        "    cnx.commit()\n",
        "\n",
        "  # Close the cursor and connection\n",
        "  cursor.close()\n",
        "  print('Done.')"
      ],
      "metadata": {
        "id": "gQbE8zI1iY-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Delimited str of Hub names"
      ],
      "metadata": {
        "id": "dRDzb16Fwk3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "function to create a string of Hub names separated by vertical bars.\n",
        "e.g. CUST|DEMO|BORON\n",
        "This uses an established connection to the SSensTek MySQL database\n",
        "which is provided to the function as the only parameter of the function.\n",
        "It returns a string containing all of the Hub names separated by vertical bars.\n",
        "The Hub names come from the from database. This string is used in a regex expression.\n",
        "\"\"\"\n",
        "def hubs_vert_bar_delim(cnx):\n",
        "    try:\n",
        "        # Connect to the database\n",
        "        cursor = cnx.cursor()\n",
        "\n",
        "        # Query the Hubs table for HubName column\n",
        "        query = \"SELECT HubName FROM Hubs\"\n",
        "        cursor.execute(query)\n",
        "\n",
        "        # Fetch all rows\n",
        "        rows = cursor.fetchall()\n",
        "\n",
        "        # Combine the rows using vertical bar delimiter\n",
        "        combined_string = '|'.join(row[0] for row in rows)\n",
        "\n",
        "        return combined_string\n",
        "\n",
        "    except mysql.connector.Error as err:\n",
        "        print(\"Error: \", err)\n",
        "\n",
        "    finally:\n",
        "        # Close the cursor\n",
        "        if cnx.is_connected():\n",
        "            cursor.close()"
      ],
      "metadata": {
        "id": "63QPf00bKXlf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}